{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00abfd6-38d9-45f1-834e-adb2c489a178",
   "metadata": {},
   "source": [
    "# Logistic regression 2 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025a9940-710b-43e2-81fb-9aee1abdf4fc",
   "metadata": {},
   "source": [
    "Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab43a11-4802-418c-b7bc-a9105319b58a",
   "metadata": {},
   "source": [
    "GridSearchCV, or Grid Search Cross-Validation, is a technique used in machine learning to tune hyperparameters of a model. Hyperparameters are parameters that are set before the learning process begins and affect the learning process itself, unlike model parameters that are learned during training. The purpose of GridSearchCV is to systematically search through a specified grid of hyperparameters to find the optimal combination that yields the best performance for a given model.\n",
    "Here's how it works:\n",
    "\n",
    "Define the Hyperparameter Grid: First, you specify a grid of hyperparameters that you want to tune. For example, if you're training a support vector machine (SVM), you might want to tune parameters like the kernel type, C (regularization parameter), and gamma.\n",
    "\n",
    "Cross-Validation: GridSearchCV performs cross-validation on each combination of hyperparameters. Cross-validation involves splitting the training data into multiple subsets (folds). The model is trained on a subset of the data (training set) and validated on the remaining subset (validation set). This process is repeated multiple times with different subsets, and the performance metrics are averaged.\n",
    "\n",
    "Model Fitting: For each combination of hyperparameters, the model is trained using the training set and evaluated using cross-validation.\n",
    "\n",
    "Select the Best Hyperparameters: After evaluating all combinations of hyperparameters, GridSearchCV selects the combination that produces the best performance based on a specified scoring metric (e.g., accuracy, F1-score, etc.).\n",
    "\n",
    "Final Model Training: Finally, the model is trained using the entire training dataset with the selected optimal hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf34322-9403-417b-a71f-47f27c31bcdb",
   "metadata": {},
   "source": [
    "Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose\n",
    "one over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e75bd1-a40a-4d23-b9f7-ff315ece0579",
   "metadata": {},
   "source": [
    "Grid Search CV: Exhaustively searches through a predefined grid of hyperparameters. It evaluates all possible combinations, suitable for smaller search spaces.\n",
    "Randomized Search CV: Randomly samples a specified number of points from the hyperparameter space. More scalable for large search spaces or limited computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110c58a-fa3f-4355-b04e-4966dbea7e2d",
   "metadata": {},
   "source": [
    "Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea6fc49-eb58-452f-99fc-88a7a8e594c3",
   "metadata": {},
   "source": [
    "\n",
    "Data leakage occurs when information from outside the training dataset is used to create a machine learning model, leading to artificially inflated performance metrics during training and poor generalization performance on unseen data. It's a significant problem because it undermines the model's ability to generalize to new, unseen data, making the model unreliable in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e46ff4-051c-48c9-824a-36728ba851ee",
   "metadata": {},
   "source": [
    "Q4. How can you prevent data leakage when building a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06990c3-ea19-4a1e-b228-27efca08dc9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Feature Selection: Exclude any features that contain information about the target variable but are not available at the time of prediction.\n",
    "\n",
    "Split Data Properly: Ensure a clear separation between training and validation/test datasets to avoid inadvertently leaking information from validation/test into training.\n",
    "\n",
    "Use Cross-Validation: Implement techniques like k-fold cross-validation to prevent overfitting and ensure model generalization without leaking information.\n",
    "\n",
    "Feature Engineering: Be cautious when creating new features to avoid incorporating future information or data that wouldn't be available in a real-world scenario.\n",
    "\n",
    "Understand the Domain: Have a thorough understanding of the data and the problem domain to identify potential sources of leakage and take appropriate precautions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8573f-6549-4ec4-858e-5908b82fbf34",
   "metadata": {},
   "source": [
    "Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590ee66-41f7-4102-abfd-ac3c2d1cb425",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that visualizes the performance of a classification model by summarizing the counts of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions on a set of data points. It's a helpful tool for evaluating the performance of a classifier, especially in binary classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f947fa-a018-4e92-9b40-77c069826002",
   "metadata": {},
   "source": [
    "Q6. Explain the difference between precision and recall in the context of a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82265ed-0150-4c0c-8eeb-8349223452b9",
   "metadata": {},
   "source": [
    "Precision: Precision measures the proportion of true positive predictions among all positive predictions. It focuses on the accuracy of positive predictions and is calculated as TP / (TP + FP).\n",
    "\n",
    "Recall: Recall measures the proportion of true positive predictions among all actual positive instances. It focuses on the model's ability to identify all positive instances and is calculated as TP / (TP + FN).\n",
    "\n",
    "In summary, precision assesses the model's accuracy in predicting positive instances, while recall evaluates its ability to capture all positive instances from the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e09b18e-c445-4b97-87cb-155425188cc2",
   "metadata": {},
   "source": [
    "Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c10c56c-bd33-440f-b384-8f439027a962",
   "metadata": {
    "tags": []
   },
   "source": [
    "Interpreting a confusion matrix helps in understanding the types of errors your model is making. Here's how:\n",
    "\n",
    "True Positives (TP): These are instances where the model correctly predicted the positive class. They represent the correct predictions made by the model.\n",
    "\n",
    "True Negatives (TN): These are instances where the model correctly predicted the negative class. They represent the correct rejections made by the model.\n",
    "\n",
    "False Positives (FP): These are instances where the model incorrectly predicted the positive class when it was actually negative (Type I error). They represent instances falsely identified as positive by the model.\n",
    "\n",
    "False Negatives (FN): These are instances where the model incorrectly predicted the negative class when it was actually positive (Type II error). They represent instances falsely identified as negative by the model.\n",
    "\n",
    "By analyzing these components of the confusion matrix, you can understand the following:\n",
    "\n",
    "Type of Errors: You can identify whether the model is making more false positives or false negatives, which helps in diagnosing the model's weaknesses.\n",
    "\n",
    "Imbalance in Classes: If there's a significant difference in the counts of TP and TN compared to FP and FN, it indicates an imbalance in the dataset or a bias in the model towards one class.\n",
    "\n",
    "Model Performance: Assessing the balance between TP, TN, FP, and FN allows you to evaluate the overall performance of the model, considering both its strengths and weaknesses.\n",
    "\n",
    "Interpreting the confusion matrix provides valuable insights into the performance of the model and helps in refining the model to minimize errors and improve its predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b1b59-7139-44e5-9747-720b033e1753",
   "metadata": {
    "tags": []
   },
   "source": [
    "Q8. What are some common metrics that can be derived from a confusion matrix, and how are they\n",
    "calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a89218-724d-4648-93a3-370fb83ec8ac",
   "metadata": {},
   "source": [
    "Accuracy: Measures the overall correctness of predictions (TP + TN) / Total.\n",
    "Precision: Measures the proportion of true positive predictions among all positive predictions. TP / (TP + FP).\n",
    "Recall (Sensitivity): Measures the proportion of true positive predictions among all actual positive instances. TP / (TP + FN).\n",
    "Specificity: Measures the proportion of true negative predictions among all actual negative instances. TN / (TN + FP).\n",
    "F1 Score: Harmonic mean of precision and recall. 2 * ((precision * recall) / (precision + recall)).\n",
    "False Positive Rate (FPR): Measures the proportion of false positive predictions among all actual negative instances. FP / (FP + TN).\n",
    "False Negative Rate (FNR): Measures the proportion of false negative predictions among all actual positive instances. FN / (FN + TP).\n",
    "These metrics provide insights into different aspects of the model's performance, helping in evaluating its effectiveness in various scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac4f65-8a5c-4392-a3cd-db993087c945",
   "metadata": {
    "tags": []
   },
   "source": [
    "Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351704d1-363b-4cfa-b040-6b50c68bc1be",
   "metadata": {},
   "source": [
    "acc = TP+TN/TP+FP+TN+FN. All these values are tken from the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34cfab-cf82-4a37-b2d2-fa8461e126a7",
   "metadata": {},
   "source": [
    "Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning\n",
    "model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b7b83-73ea-4774-91cc-c190427356c8",
   "metadata": {},
   "source": [
    "Analyzing Class Imbalances: If there are significant differences in the counts of true positives/negatives versus false positives/negatives, it indicates potential class imbalances or biases in the dataset or model.\n",
    "\n",
    "Identifying Specific Error Patterns: Examining the distribution of false positives and false negatives can reveal specific patterns or trends in misclassifications, highlighting areas where the model performs poorly.\n",
    "\n",
    "Evaluating Model Generalization: Comparing performance metrics across different subsets of the dataset (e.g., training vs. validation/test) can help assess the model's generalization ability and identify overfitting or underfitting issues.\n",
    "\n",
    "Detecting Sensitivity to Class Distributions: Changes in model performance with variations in class distributions can indicate sensitivity to imbalanced data, highlighting the need for techniques like class weighting or resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052f134-a2ab-4915-b196-f9696475f3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9b03f-0349-4161-8e3e-ca252b35d13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607d128-16cc-4477-8071-f1b2eae03c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88b101-04a3-46b3-8813-e30c0fdd05cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544d93f-b5aa-4d99-b492-a4810e57b09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56c40c-f7e7-4232-9f5e-00a3d308322b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d042ff-bec5-41b0-8bb7-6d67155c37e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9a092-f966-4c89-a533-7262bb114d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8e878-1df7-4ded-8f43-11b3ccfe25d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ddd42a-7735-41cb-837c-6c394156ace2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedf9d9-ab5a-40cc-8e94-0307f31ef2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40909a-5e9a-46b4-8fbf-b7b9dd3acb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf20806-432f-4079-b94c-fb6dcaa24af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f94c1-713b-4234-b5ba-5581df7c7e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc6a01-5e5e-4d73-8ab5-03909becf4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b0d49-e92e-4d32-a08a-7cdc994f8b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff1779-a209-455e-8f55-ca480fd50535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99cc655-96a3-42ca-9904-4d8c6a08c8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cf091-8ea6-4fe1-8644-e98e4b57c2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1aec51-6c7b-41e9-b6e2-a66998091a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219dbd2e-11a4-461b-be7b-9244af966d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369519cc-48a1-479e-8bf9-f28ee0972178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2758f-deb5-46e2-ba8f-80d8ec191b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce167dd2-f806-4b8a-a836-183f78c941c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf88e16-49d1-45cf-bde8-1dd80aafeeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffc6a9-5b33-4c1f-8a51-2ab7a03b9f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e634311-55bb-4178-a2ae-6c51495ea44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
