{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f94b74-b5ca-4011-8062-0a2545d0bb45",
   "metadata": {},
   "source": [
    "# Feature Engineering Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bba54d-4fc0-402f-9ef5-ef939b826a05",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5419456e-95ee-4054-acee-ca50f79f019d",
   "metadata": {},
   "source": [
    "Min Max scaling also called normalisation is a method which converts the data points in the range of 0-1. So when training the ML model, there are few algorithms which works on distance metrics and data might be in different scales like kg, meter, etc. So we need to convert this into a scaled value and min max scaling is a technique for that. Scaled Value = (X - X_min) / (X_max - X_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2391ef53-01c8-404e-bfc8-08eef8986767",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b36eb-7e16-47db-b544-e8b02999ebbe",
   "metadata": {},
   "source": [
    "Unit Vector Scaling, also known as L2 normalization, is a technique used in feature scaling to transform data such that it lies on the unit hypersphere or unit circle. This technique is primarily applied to normalize data in a way that all data points have the same scale, making them suitable for machine learning algorithms that are sensitive to the magnitude of features.Min-Max Scaling: This technique scales the data linearly between a specified range (commonly between 0 and 1 or -1 and 1). It is useful when you want to maintain the original distribution of the data while rescaling it. Min-Max scaling is defined as:\n",
    "\n",
    "Scaled Value = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "Unit Vector Scaling: This technique doesn't scale data within a specific range. Instead, it transforms the data into unit vectors, effectively preserving the direction of each data point while making sure that all vectors have a length of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25abbed-9a5b-4fe5-b4e6-acc7dc69352d",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a7b23-5b5b-45ea-aa3d-1bf0fd0e5cd4",
   "metadata": {
    "tags": []
   },
   "source": [
    " Principal Component Analysis (PCA) is a statistical technique used in data analysis and machine learning to reduce the dimensionality of a dataset while preserving as much of the variance in the data as possible. PCA accomplishes this by transforming the original features into a new set of orthogonal (uncorrelated) features called principal components. These principal components are linear combinations of the original features and are ranked by the amount of variance they explain in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fd1b4-20aa-4ac4-8d49-38be716a2235",
   "metadata": {
    "tags": []
   },
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d8bb39-95c2-4a72-b8fb-36a5a4b795f7",
   "metadata": {},
   "source": [
    "Feature Extraction is the process of selecting and extracting the important features of raw data. It also aims in reduced dimensions of the data while retaining as much info. PCA is one such technique where we can acheive the same goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0d967-53cb-452c-8e62-043f42ce9c9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75f1c4-84bb-4185-a1ea-c6250f3c7bd7",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler()\n",
    "min_max.fit_transform(df[['price','rating','delivery time']])\n",
    "The above code helps for min max scalimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94738feb-21e4-4dba-8e7e-a48691c7c005",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ece14-857d-4f57-9980-1c65c8b00d0e",
   "metadata": {},
   "source": [
    "We will use PCA by finding the best fit line between the 2 features and the points that lie n the best fit line wil be the data points hence the dimesnion is reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3807e27-8738-41c5-926d-c6d197d49a01",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9601ed-c430-4ae1-8dfd-5ec18606ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.21052632],\n",
       "       [0.47368421],\n",
       "       [0.73684211],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "min_max=MinMaxScaler()\n",
    "df = pd.DataFrame([1,5,10,15,20])\n",
    "min_max.fit_transform(df[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925303ea-6387-4bc4-8e8c-7212cc840945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32f0db-d4ec-43f4-98bb-42e74944baa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e7fa2-1b3e-4f09-8c6f-137da34e39b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d00dd-5861-4930-9099-46bb2b77bf31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef68664e-9853-4237-86bf-da6d19478d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941ad8e-5139-4674-8186-e856a7ee185a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10abe8-9f02-4792-b010-a936b1f6f2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30020d7-7f23-419b-a726-7f460b825102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f3a18-18ea-4bf0-a30e-c6a91bc08299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f0c10-e45b-40bf-9e77-397a7d32fe84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe9b0e-4cc3-4158-8712-2c4ceef9edb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43a90f-e00b-4e70-b75e-24ec7916d570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1cb90c-8c69-4655-a7b0-0055bb76d871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c0eb8-e01c-4cf8-bee2-94c1e09987f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d28eff-8c05-4bd8-b3e3-181871c7526c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd388862-9a31-4cc4-ad70-18fde3f0adb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee6d3d2-efdf-4fa2-a148-3ebef9ded9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd697295-04fb-4029-a583-b521b7e2aa95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab6a4b4-1c79-4148-acff-853fcb38480c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cd2e6-cc60-417b-a97f-aeae063c11ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139d4cc-a5fa-4f5d-83bd-409f714c23ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439a395-1335-46b7-b9d1-148be64e05f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8f9cf-38b3-4613-8418-b09858aa7dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f90207-adaa-4029-a4f6-e5adb7e87e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa4104-cce8-43e1-b0a4-07c5d3402eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1a2c3-8b22-4c93-837b-b705a84e04a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528553d-aa71-41bc-824d-0f468f354744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0db5f-f904-4bca-a28f-915e8d4eaa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f0e4a-bc96-4978-a8f0-48bbe1552b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1002b-f69d-49da-a3a0-f12e918d2274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866824cd-e407-4a04-add6-4ad6f59fce81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
