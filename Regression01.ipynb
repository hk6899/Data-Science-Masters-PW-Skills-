{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1660c4b4-e56b-45ce-8bd4-4386a3707f5d",
   "metadata": {},
   "source": [
    "Assignment Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573edb0-78cb-4a7b-a8eb-ee9c70e3e92b",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ccc0d-bd0a-42ed-be93-1250e4130874",
   "metadata": {},
   "source": [
    "Simple linear regression has one independent feature(i/p) and one dependent feature(o/p). Here we use a best fit line to predict. Eg : Calculate weight w.r.t heigh\n",
    "Multiple linear regression has more than one independent feature(i/p) and one dependent feature(o/p). Here we use a best fit plane to predict.Eg House price prediction with house features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba85e5-d5ba-40f0-8fe3-4c4fc6ae0e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e26c20eb-0806-498d-ab3e-04e6e42e95a5",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419ea201-3cab-44bd-b9a5-6870f6570d3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Linearity: The relationship between the independent variable(s) and the dependent variable is assumed to be linear. This means that a change in the independent variable(s) is associated with a constant change in the dependent variable.\n",
    "\n",
    "Independence: The observations in the dataset should be independent of each other. In other words, the value of the dependent variable for one observation should not be influenced by the value of the dependent variable for another observation.\n",
    "\n",
    "Homoscedasticity (Constant Variance): The variance of the residuals (the differences between the observed and predicted values) should be constant across all levels of the independent variable(s). This assumption is violated when the spread of residuals varies as the independent variable(s) change.\n",
    "\n",
    "Normality of Residuals: The residuals (the differences between the observed and predicted values) should be approximately normally distributed. This assumption is not crucial for large sample sizes due to the Central Limit Theorem, but it can be important for small sample sizes.\n",
    "\n",
    "No Perfect Multicollinearity: In multiple linear regression (involving more than one independent variable), there should not be perfect linear relationships among the independent variables. Multicollinearity can make it difficult to assess the individual contributions of each independent variable to the dependent variable.\n",
    "\n",
    "We can vheck these assumptions hold by using various visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e12d57-294c-44a8-89cc-50331898a5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0ffca71-6f79-4f0d-bebf-878c7a0584b2",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a772652f-986d-4926-a09c-25d40e512257",
   "metadata": {},
   "source": [
    "Intercept is for x=0, what is the value of y. Slope s for one unit movement of x, what is the movement in y.\n",
    "Eg: Salarymof an employee, when experience(x=0), there is some salary, so intercept is not 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb42bc5-234c-47ba-8a13-44ea0ad115c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39aa3eb9-e5ca-449e-9e70-b2a4e0539e2a",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b518db1f-645d-4682-90d3-c2dbef87c450",
   "metadata": {},
   "source": [
    "Gradient descent is an optimizatin technique used to minimizze the cost function or loss function.  The goal of gradient descent is to iteratively move towards the minimum of the cost function by adjusting the model parameters. It's particularly useful in training machine learning models, where the objective is to find the optimal set of parameters that minimize the difference between the predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be37839-6c15-4e80-947a-15e6f5e1b94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d5fbcca-9991-4010-8dae-e1fdcddab3fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec18f13-e4b9-46e3-ab13-c7ed66858b93",
   "metadata": {},
   "source": [
    "Multiple linear regression has more than one independent feature(i/p) and one dependent feature(o/p). Here we use a best fit plane to predict.\n",
    "Simple linear regression has one independent feature(i/p) and one dependent feature(o/p). Here we use a best fit line to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4781d66-8882-4955-aced-3089114261d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1eb5deb-4cbd-40a2-8290-4fed0155eb34",
   "metadata": {
    "tags": []
   },
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88629231-12bf-4491-8eba-42c4d7d2a76f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Multicollinearity is a phenomenon that occurs in multiple linear regression when two or more independent variables in a model are highly correlated. This high correlation can cause issues in the estimation of the regression coefficients and make it challenging to isolate the individual effect of each variable on the dependent variable.Detection of Multicollinearity:\n",
    "Correlation Matrix: Examine the correlation matrix of the independent variables. High correlation coefficients (close to +1 or -1) indicate potential multicollinearity.\n",
    "\n",
    "Variance Inflation Factor (VIF): Calculate the VIF for each independent variable. VIF quantifies how much the variance of a regression coefficient is increased due to multicollinearity. A VIF greater than 10 is often considered indicative of multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7557791-07ab-4a87-b063-f7fd7f4a7599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5fa8a3a-c522-4cf9-9c6a-96cd87affc33",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e87f4-a3bf-4103-a4a6-e8608214d463",
   "metadata": {},
   "source": [
    "In contrast to linear regression, which assumes a linear relationship, polynomial regression allows for more flexibility by accommodating curved or nonlinear patterns in the data. The key difference lies in the form of the regression equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6d195-6a8a-4364-a21e-5641bbb17520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9511ca3-04e5-41cb-9dea-e0d58d77da59",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6462eee-9242-4e17-9f8c-0b35275bbe63",
   "metadata": {},
   "source": [
    "Polynomial regression allows for the modeling of nonlinear relationships between the independent and dependent variables. It can capture more complex patterns in the data that linear regression cannot.\n",
    "Useful when the true relationship between variables involves higher-order terms, such as quadratic or cubic patterns.\n",
    "Can result in a more accurate fit to the training data when the relationship is genuinely nonlinear.\n",
    "High-degree polynomials can lead to overfitting, capturing noise in the data rather than the underlying pattern. Overfit models may perform poorly on new, unseen data.\n",
    "Higher-degree polynomials increase the complexity of the model, making it more computationally expensive and potentially harder to manage.\n",
    "Extrapolating beyond the range of the observed data can be risky, as polynomial models can produce unpredictable results outside the observed range.\n",
    "In summary, while linear regression is suitable for capturing linear relationships, polynomial regression provides a more flexible framework for modeling nonlinear relationships by introducing polynomial terms of higher degrees. The choice between them depends on the underlying patterns in the data and the assumptions about the relationship between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4514e9-2901-42d0-8600-f3ccb752d113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5913402d-9352-40e8-bede-492b58c9e18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d89e6a-1bb3-4deb-8a75-91a6eb886c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff18672-cc51-4891-b4e6-539c803b89f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31660881-9067-4f27-ad99-d9938307ea40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c64c4e-2883-4c3e-ade2-00ebb47fa51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20d112-ccac-4583-9257-ab195a29f32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c0b5e-2f85-4499-b588-241bfc3690c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
